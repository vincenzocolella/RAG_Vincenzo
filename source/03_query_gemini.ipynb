{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VincenzoColella\\Documents\\GitHub\\RAG_Vincenzo\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\VincenzoColella\\AppData\\Local\\Temp\\ipykernel_24012\\707179182.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat interattiva con Gemini (digita 'exit' per uscire):\n",
      "Gemini: Nessun evento trovato nel periodo richiesto.\n",
      "\n",
      "Gemini: Nessun evento trovato nel periodo richiesto.\n",
      "\n",
      "Gemini: Gli eventi dell'anno scorso (2024) sono:\n",
      "\n",
      "* 2024-01-06 00:00 - 2024-01-07 00:00: Vau da PostFinance\n",
      "* 2024-02-15 17:00 - 2024-02-15 18:00: Unghie\n",
      "* 2024-04-27 15:00 - 2024-04-27 16:00: 5km de Lausanne alle 17\n",
      "\n",
      "\n",
      "Gemini: Gli eventi di tre anni fa (rispetto al 24 Giugno 2025) ricadono nel periodo compreso tra il 24 Giugno 2022 e il 24 Giugno 2023.  Gli eventi di questo periodo sono:\n",
      "\n",
      "* 2022-05-12 15:30 - 2022-05-12 16:30: Sapienza AI seminario\n",
      "* 2022-06-27 00:00 - 2022-06-28 00:00: Genitori CR\n",
      "* 2022-07-21 14:30 - 2022-07-21 15:30: Louvre\n",
      "* 2023-03-11 07:00 - 2023-03-11 08:00: Padel con Adriano\n",
      "* 2023-05-09 00:00 - 2023-05-10 00:00: Festa marghe\n",
      "* 2023-07-09 00:00 - 2023-07-10 00:00: Concerto Coez\n",
      "\n",
      "\n",
      "Gemini: Nessun evento trovato nel periodo richiesto.  I dati forniti sono informazioni personali e professionali, non eventi con date di inizio e fine.\n",
      "\n",
      "Gemini: Nessun evento trovato nel periodo richiesto.\n",
      "\n",
      "Uscita. A presto!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today().isoformat()\n",
    "\n",
    "\n",
    "# Percorso al file della chiave\n",
    "api_key_path = os.path.join(\"config\", \"google_api\")\n",
    "try:\n",
    "    with open(api_key_path, \"r\") as f:\n",
    "        api_key = f.read().strip()\n",
    "except FileNotFoundError:\n",
    "    api_key = None\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"La chiave API di Google non è stata trovata. Assicurati che il file 'google_api' esista nella cartella 'config'.\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Carica embedding e indice FAISS\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faiss_index = FAISS.load_local(\n",
    "    \"../embeddings/faiss_index_hf\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "def ask_gemini(query, top_k=5):\n",
    "    risultati = faiss_index.similarity_search(query, k=top_k)\n",
    "    if not risultati:\n",
    "        return \"Nessun documento rilevante trovato.\"\n",
    "\n",
    "    contesto = \"\\n\\n\".join([r.page_content for r in risultati])\n",
    "    prompt = f\"\"\"\n",
    "Sei un assistente personale che ha a disposizione una lista di eventi con date di inizio e fine.\n",
    "La data odierna è: {today}\n",
    "\n",
    "La domanda è: {query}\n",
    "\n",
    "Dai eventi forniti, rispondi elencando solo quelli che ricadono nel periodo di tempo indicato nella domanda, se la domanda lo richiede.\n",
    "Se la domanda non specifica un periodo, rispondi con tutti gli eventi rilevanti.\n",
    "\n",
    "Se non trovi eventi rilevanti, rispondi con \"Nessun evento trovato nel periodo richiesto.\"\n",
    "\n",
    "Ecco i dati disponibili (eventi):\n",
    "\n",
    "{contesto}\n",
    "\n",
    "Risposta:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    modello = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    risposta = modello.generate_content(prompt)\n",
    "    return risposta.text or \"Il modello non ha generato una risposta.\"\n",
    "\n",
    "def main():\n",
    "    print(\"Chat interattiva con Gemini (digita 'exit' per uscire):\")\n",
    "    while True:\n",
    "        domanda = input(\"\\nTu: \")\n",
    "        if domanda.strip().lower() in [\"exit\", \"esci\", \"quit\"]:\n",
    "            print(\"Uscita. A presto!\")\n",
    "            break\n",
    "\n",
    "        print(\"Gemini:\", end=\" \")\n",
    "        try:\n",
    "            risposta = ask_gemini(domanda)\n",
    "            print(risposta)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErrore: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
